# M觀點 EP244 簡報：AI 產業關鍵動態與未來洞察

## 執行摘要

本簡報綜合分析了近期人工智慧（AI）產業的三大關鍵動態，深入探討了技術創新、市場策略及未來發展路徑。首先，Anthropic 推出的 Claude「Skills」功能，雖然技術本身不複雜，但其高度實用性被視為提升 AI 模型價值的典範，預期將引領業界潮流。其次，OpenAI 宣布開放成人內容，此舉反映了在技術優勢縮小、市場競爭加劇的背景下，透過內容策略鞏固並擴大其龐大用戶基礎的戰略意圖。

最為關鍵的是，本簡報深度剖析了 AI 巨擘 Andrej Karpathy 的最新訪談。Karpathy 認為，當前的 AI Agent 發展尚處於「十年演進期」的開端，而非短期內即可成熟。他指出現行 AI 技術的兩大核心瓶頸：對「強化學習」的過度依賴及其訊號簡陋的缺陷，以及大型語言模型（LLM）在架構上的三大根本性問題——過度依賴知識而缺乏泛化能力、無法持續學習、以及使用合成資料訓練將導致「模型崩潰」。Karpathy 提出的「幽靈 AI」與「動物 AI」之分野，為理解 AGI 的未來路徑提供了深刻的哲學框架，指出當前 LLM 僅是召喚過去知識的「幽靈」，真正的 AGI 必須是能從經驗中學習通用原則的「動物」。

## Anthropic Claude 推出「Skills」功能：AI 實用性的重大革新

Anthropic 為其 AI 模型 Claude 推出的「Skills」（技能）功能，被認為是一項對用戶價值極高的更新。儘管並非高深的技術突破，但它解決了使用者在與 AI 互動時的關鍵痛點，並預期將引發業界的跟進浪潮。

### 「Skills」功能的核心概念

「Skills」功能允許使用者為特定類型的任務，預先載入一個包含詳細指令、流程、額外知識與資源的「技能包」。這相當於為通用的大型語言模型（LLM）在執行特定任務前，裝上一個專門優化的「外掛」。

- **任務導向的強化：** 當模型需要處理 A 任務時，可以載入 A 技能包；處理 B 任務時，則換上 B 技能包。
- **類比與說明：**
  - **RPG 遊戲比喻：** 如同在角色扮演遊戲中，面對不同屬性的怪物時，玩家會切換使用剋制的武器或魔法（例如用錘子打史萊姆，用火系魔法打冰雪怪人）。「Skills」就是為 AI 提供應對不同任務的「專屬技能」。
  - **資深主管交辦任務比喻：** 一個優秀的主管在交辦任務給新手時，會提供極其詳盡的說明，包括：
    1. **明確目標與關鍵點：** 指出任務的核心要素（如分析財報時的營收成長率、製程佔比等）。
    2. **詳細步驟與方法論：** 指導如何分析數據、需考慮的背景因素、趨勢判讀等。
    3. **提供範例與參考資料：** 給予過往的優秀報告作為參考，並點評其優劣。
    4. **規範輸出格式：** 明確要求圖表類型（如長條圖而非折線圖）、顏色、數據時間跨度等。
    5. **建立驗證與檢查流程：** 建議使用其他工具或 AI 進行交叉驗證。

「Skills」功能將上述這種複雜、詳盡的指導流程，打包成一個可重複使用的檔案。使用者只需建立一次，未來在處理同類型任務時，即可直接調用，大幅提升效率與產出品質。

### 技術實現與市場影響

此功能的技術核心是將一系列優化的 Prompts、腳本、知識庫與外部資源連結，整合在一個檔案中，讓 LLM 在執行任務前先行讀取。其價值不在於技術的複雜性，而在於對使用者體驗的巨大提升。

| 特點               | 描述                                                         |
| ------------------ | ------------------------------------------------------------ |
| **高度實用性**     | 解決了使用者每次都需重複輸入複雜指令的痛點，類似於瀏覽器的「我的最愛」功能，簡單卻不可或缺。 |
| **降低使用門檻**   | 對於不擅長下指令的使用者，可以下載並使用專家建立的「技能包」，立即提升 AI 的表現能力，促進 AI 能力的普及化。 |
| **引領業界風潮**   | 主講人預測，如同 Anthropic 過去推出的 `MCP`（Model-Centric Protocol）通訊協定一樣，「Skills」功能將在三個月內被 OpenAI、Google、XAI 等競爭對手表仿，成為業界標準配備。 |
| **突顯使用者體驗** | 此功能突顯了 Anthropic 在改善使用者體驗方面的洞察力，相較之下，部分廠商可能過於專注 AGI 的宏大目標，而忽略了當前用戶的實際需求。 |

## OpenAI 政策轉向：開放成人內容的策略考量

OpenAI 宣布將於 2024 年 12 月起，允許通過年齡驗證的成年用戶使用其 AI 服務生成成人與情色內容。此舉被視為在激烈的市場競爭下，為鞏固並活化其龐大用戶群所採取的關鍵策略。

### 政策變更內容與動機

OpenAI 的官方立場是「將成年用戶當作成年人對待」（Treat adult users like adults），表明其無意扮演「道德警察」的角色。在確保能有效防止青少年接觸的前提下，滿足成年用戶的需求。

此策略背後的主要動機源於白熱化的市場競爭：

1. **技術護城河縮小：** 隨著各家 AI 技術水平逐漸拉近，OpenAI 已不具備絕對的技術領先優勢。
2. **尋求差異化：** 在功能與模型能力趨同的市場中，開放成人內容成為一個能立即吸引並留存特定用戶群的差異化策略。
3. **活化龐大用戶基礎：** ChatGPT 擁有高達 8 億的週活躍用戶，透過滿足這部分潛在需求，能有效提升用戶黏著度與付費意願。
4. **市場潛力：** 歷史證明，遊戲、色情與賭博是在網路世界中最具商業潛力的三大領域。在遊戲領域已被充分開發後，觸及成人內容是符合商業邏輯的延伸。

### 開放範圍推測與市場反應

預期開放的內容將以文字為主，而涉及聲音與影像的部分則可能因爭議較大而暫緩。

- **較可能開放：**
  - 色情小說、浪漫文學創作。
  - 情色主題的對話與探討。
  - 虛擬角色扮演（情色聊天）。
- **較不可能開放：**
  - 語音形式的互動（如電話性愛）。
  - 生成露骨的色情圖像或影片。

主講人預測，此舉將引發不同廠商的差異化反應：

- **XAI（馬斯克）：** 預期會迅速跟進，因其風格向來不受傳統道德框架束縛。
- **Google & Anthropic：** 可能不會跟進，因為這兩家公司相對更注重企業形象與所謂的「道德潔癖」。

## Andrej Karpathy 對當前 AI 發展的深度剖析

前特斯拉 AI 總監、OpenAI 創始成員之一的 Andrej Karpathy 在一次深度訪談中，提出了對當前 AI 發展路徑的批判性反思，其觀點對於理解 AGI 的未來至關重要。

### AI Agent 的發展時間表：「十年演進」而非「元年爆發」

Karpathy 認為，業界對 AI Agent 的短期發展過於樂觀。他主張，我們正進入的是一個長達十年的「AI Agent 的十年」（Decade of Agents），而非單一的「AI Agent 之年」（Year of Agents）。

- **現狀：** 當前的 AI Agent（如程式碼助手）雖然實用，但距離完全取代人類專家仍有相當大的差距。
- **未來預期：** 一個真正成熟、強大的 AI Agent 生態系，預計要到 2035 年左右才會成形。這並非悲觀，而是體現了技術發展的長期性與艱鉅性。

### 當前 AI 技術的核心缺陷

Karpathy 指出，目前主流 AI 技術存在根本性的局限，這也是為何他認為通往 AGI 的道路依然漫長。

#### 1. 強化學習（Reinforcement Learning）的局限性

他形容強化學習是「一個很爛的學習方法，只是比我們目前發現的任何其他方法都好」。其主要缺陷在於：

- **訊號過於簡陋：** 強化學習僅在任務結束時給予一個單一的獎勵或懲罰訊號（例如 `+1` 或 `-1`），卻無法對過程中的數十個步驟進行細緻的回饋。
- **低效且充滿雜訊：** 這種模式可能獎勵到一個「碰巧得出正確答案的錯誤過程」，導致學習效率低下。
- **與人類學習的差異：** 人類學習充滿了持續的、內在的評估與修正，而非僅依賴最終結果。以寫作為例，人類在寫下每一句話時都會進行即時的自我回饋與調整，這遠比 AI 等到整篇文章完成後才獲得一個總分要精細得多。

#### 2. 大型語言模型（LLM）的架構性問題

Karpathy 認為當前的 LLM 架構存在三大根本性缺陷，使其難以演化為真正的智慧體。

| 缺陷                           | 詳細說明                                                     | 案例闡述                                                     |
| ------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **過度依賴知識，缺乏泛化能力** | LLM 擁有近乎無限的記憶力，使其傾向於透過龐大數據庫中的統計關聯性來預測下一個詞元，而非學習通用的、抽象的原則。人類則因記憶力有限，被迫學習並依賴「泛化」的原則。 | 將一台搭載 FSD 的特斯拉傳送到一個交通規則、車輛外型完全不同的「異世界」，FSD 將完全失靈。但一個人類駕駛員在被告知新規則後，能很快適應，因為人類依賴的是通用的駕駛原則。 |
| **缺乏持續學習能力**           | LLM 無法從與用戶的單次對話中進行實時學習與模型更新。其進化依賴於開發者定期收集數據、調整架構後進行的「批量式」重新訓練。 | 人類大腦每天都在學習，透過睡眠等機制不斷重塑神經連接。LLM 則像是一個靜態的知識庫，無法持續性地自我演進。 |
| **合成資料的崩潰風險**         | 為了突破訓練資料不足的瓶頸，業界普遍採用 AI 生成的「合成資料」。然而，過度依賴合成資料會導致「模型崩潰」（Model Collapse），即模型越訓練越笨。 | 原因是 AI 生成的資料缺乏足夠的「熵」（Entropy，可理解為混亂度或隨機性）。人類社會的進步依賴於年輕一代不斷提出天馬行空的、高熵值的想法，而 AI 產生的資料往往是重複、模式化的，無法提供模型進化所需的多樣性。 |

### 兩種 AI 智能模式：「幽靈」（Ghost） vs. 「動物」（Animal）

這是 Karpathy 整個論述的核心，他將當前 AI 與理想中的 AGI 劃分為兩種截然不同的模式。

- **幽靈 AI (Ghost AI) - 當前的 LLMs：**
  - **本質：** 召喚（Summoning）人類歷史上所有知識留下的「數位幽靈」。它們是過去智慧的統計學回響，而非一個獨立的思考實體。
  - **學習方式：** 從靜態的文本和數據中學習。
  - **能力：** 在數據充足的領域表現出色，但無法真正「理解」世界（例如，它知道「太陽在藍天上」這句話，卻無法體驗其含義），並且在數據稀疏或需要通用原則的場景中會失敗或產生幻覺。
  - **代表任務：** 知識問答、文本生成。
  - **弱點任務：** 操作電腦、瀏覽器等需要適應動態、非標準化環境的任務，因為這些任務極度依賴通用原則，而非固定的數據模式。
- **動物 AI (Animal AI) - 理想中的 AGI：**
  - **本質：** 一個真正從與物理世界和數位世界的互動中學習的智慧生命體。
  - **學習方式：** 從親身經驗、試錯和互動中學習，從而內化出通用的原則。
  - **能力：** 擁有真正的理解能力和強大的泛化能力，不會產生幻覺，能夠處理全新的、前所未見的問題。
  - **未來路徑：** Karpathy 推測，未來的路徑可能是利用我們現有能力構建出的強大「幽靈 AI」，作為模擬器或導師，來訓練和引導「動物 AI」的誕生。

### 主持人觀點：未來 AI 的協作模式

基於 Karpathy 的理論，主講人提出了他對未來 AI 形態的猜想：

- **協作而非替代：** 未來的頂級 AI 系統，可能不是單一的「動物 AI」，而是一個由「動物 AI」擔任總指揮官，多個專精不同領域的「幽靈 AI」擔任參謀的協作體系。
- **分工模式：**
  - **動物 AI (指揮官):** 負責運用通用原則進行決策、整合資訊、制定戰略。
  - **幽靈 AI (專家顧問):** 負責提供龐大、精準的領域知識和數據分析。
- **現實類比：** 這種類比當下人類專家（如主講人本人）使用 AI 的方式。專家本身作為「動物」核心，利用多個 AI（幽靈）工具來獲取和交叉驗證資訊，最終運用自己的判斷力和通用原則，形成高品質的洞察。